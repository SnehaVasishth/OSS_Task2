{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4b5ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\Scripts\\wandb.exe\\__main__.py\", line 7, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\click\\core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\wandb\\cli\\cli.py\", line 97, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\wandb\\cli\\cli.py\", line 241, in login\n",
      "    wandb.login(relogin=relogin, key=key, anonymous=anon_mode, host=host, force=True)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_login.py\", line 77, in login\n",
      "    configured = _login(**kwargs)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_login.py\", line 292, in _login\n",
      "    wlogin.configure_api_key(key)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_login.py\", line 176, in configure_api_key\n",
      "    apikey.write_key(self._settings, key)\n",
      "  File \"C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\apikey.py\", line 224, in write_key\n",
      "    raise ValueError(\"API key must be 40 characters long, yours was %s\" % len(key))\n",
      "ValueError: API key must be 40 characters long, yours was 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\sneha\\anaconda3\\lib\\site-packages (0.13.4)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: pathtools in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (61.2.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (1.9.10)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\sneha\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-wheel-kb6wk8c2'\n",
      "       cwd: C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\n",
      "  Complete output (52 lines):\n",
      "  \n",
      "  -------- Configuring Module: cuda --------\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  *** WARNING: Cannot check compute capability\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  \n",
      "  ************************************************************\n",
      "  * CuPy Configuration Summary                               *\n",
      "  ************************************************************\n",
      "  \n",
      "  Build Environment:\n",
      "    Include directories: ['C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\cupy/_core/include\\\\cupy\\\\cub', 'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\cupy/_core/include']\n",
      "    Library directories: []\n",
      "    nvcc command       : (not found)\n",
      "    hipcc command      : (not found)\n",
      "  \n",
      "  Environment Variables:\n",
      "    CFLAGS          : (none)\n",
      "    LDFLAGS         : (none)\n",
      "    LIBRARY_PATH    : (none)\n",
      "    CUDA_PATH       : (none)\n",
      "    NVTOOLSEXT_PATH : (none)\n",
      "    NVCC            : (none)\n",
      "    HIPCC           : (none)\n",
      "    ROCM_HOME       : (none)\n",
      "  \n",
      "  Modules:\n",
      "    cuda      : No\n",
      "      -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h', 'nvrtc.h']\n",
      "      -> Check your CFLAGS environment variable.\n",
      "  \n",
      "  ERROR: CUDA could not be found on your system.\n",
      "  \n",
      "  HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "        Please consider using binary packages instead.\n",
      "  \n",
      "  Please refer to the Installation Guide for details:\n",
      "  https://docs.cupy.dev/en/stable/install.html\n",
      "  \n",
      "  ************************************************************\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\setup.py\", line 86, in <module>\n",
      "      ext_modules = cupy_setup_build.get_ext_modules(True, ctx)\n",
      "    File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\install\\cupy_builder\\cupy_setup_build.py\", line 491, in get_ext_modules\n",
      "      extensions = make_extensions(ctx, compiler, use_cython)\n",
      "    File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\install\\cupy_builder\\cupy_setup_build.py\", line 306, in make_extensions\n",
      "      raise Exception('Your CUDA environment is invalid. '\n",
      "  Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for cupy\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\sneha\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\n",
      "  Complete output (52 lines):\n",
      "  \n",
      "  -------- Configuring Module: cuda --------\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  *** WARNING: Cannot check compute capability\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  \n",
      "  ************************************************************\n",
      "  * CuPy Configuration Summary                               *\n",
      "  ************************************************************\n",
      "  \n",
      "  Build Environment:\n",
      "    Include directories: ['C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\cupy/_core/include\\\\cupy\\\\cub', 'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\cupy/_core/include']\n",
      "    Library directories: []\n",
      "    nvcc command       : (not found)\n",
      "    hipcc command      : (not found)\n",
      "  \n",
      "  Environment Variables:\n",
      "    CFLAGS          : (none)\n",
      "    LDFLAGS         : (none)\n",
      "    LIBRARY_PATH    : (none)\n",
      "    CUDA_PATH       : (none)\n",
      "    NVTOOLSEXT_PATH : (none)\n",
      "    NVCC            : (none)\n",
      "    HIPCC           : (none)\n",
      "    ROCM_HOME       : (none)\n",
      "  \n",
      "  Modules:\n",
      "    cuda      : No\n",
      "      -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h', 'nvrtc.h']\n",
      "      -> Check your CFLAGS environment variable.\n",
      "  \n",
      "  ERROR: CUDA could not be found on your system.\n",
      "  \n",
      "  HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "        Please consider using binary packages instead.\n",
      "  \n",
      "  Please refer to the Installation Guide for details:\n",
      "  https://docs.cupy.dev/en/stable/install.html\n",
      "  \n",
      "  ************************************************************\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\setup.py\", line 86, in <module>\n",
      "      ext_modules = cupy_setup_build.get_ext_modules(True, ctx)\n",
      "    File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\install\\cupy_builder\\cupy_setup_build.py\", line 491, in get_ext_modules\n",
      "      extensions = make_extensions(ctx, compiler, use_cython)\n",
      "    File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\install\\cupy_builder\\cupy_setup_build.py\", line 306, in make_extensions\n",
      "      raise Exception('Your CUDA environment is invalid. '\n",
      "  Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for cupy\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\sneha\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-record-avgyzqqo\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\sneha\\anaconda3\\Include\\cupy'\n",
      "         cwd: C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\n",
      "    Complete output (52 lines):\n",
      "    \n",
      "    -------- Configuring Module: cuda --------\n",
      "    Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    **************************************************\n",
      "    *** WARNING: Cannot check compute capability\n",
      "    Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    **************************************************\n",
      "    \n",
      "    ************************************************************\n",
      "    * CuPy Configuration Summary                               *\n",
      "    ************************************************************\n",
      "    \n",
      "    Build Environment:\n",
      "      Include directories: ['C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\cupy/_core/include\\\\cupy\\\\cub', 'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\cupy/_core/include']\n",
      "      Library directories: []\n",
      "      nvcc command       : (not found)\n",
      "      hipcc command      : (not found)\n",
      "    \n",
      "    Environment Variables:\n",
      "      CFLAGS          : (none)\n",
      "      LDFLAGS         : (none)\n",
      "      LIBRARY_PATH    : (none)\n",
      "      CUDA_PATH       : (none)\n",
      "      NVTOOLSEXT_PATH : (none)\n",
      "      NVCC            : (none)\n",
      "      HIPCC           : (none)\n",
      "      ROCM_HOME       : (none)\n",
      "    \n",
      "    Modules:\n",
      "      cuda      : No\n",
      "        -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h', 'nvrtc.h']\n",
      "        -> Check your CFLAGS environment variable.\n",
      "    \n",
      "    ERROR: CUDA could not be found on your system.\n",
      "    \n",
      "    HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "          Please consider using binary packages instead.\n",
      "    \n",
      "    Please refer to the Installation Guide for details:\n",
      "    https://docs.cupy.dev/en/stable/install.html\n",
      "    \n",
      "    ************************************************************\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\setup.py\", line 86, in <module>\n",
      "        ext_modules = cupy_setup_build.get_ext_modules(True, ctx)\n",
      "      File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\install\\cupy_builder\\cupy_setup_build.py\", line 491, in get_ext_modules\n",
      "        extensions = make_extensions(ctx, compiler, use_cython)\n",
      "      File \"C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-install-raxzt6dd\\cupy_eda554613f914b8ea3110116ea5bd7ee\\install\\cupy_builder\\cupy_setup_build.py\", line 306, in make_extensions\n",
      "        raise Exception('Your CUDA environment is invalid. '\n",
      "    Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\sneha\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-install-raxzt6dd\\\\cupy_eda554613f914b8ea3110116ea5bd7ee\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\sneha\\AppData\\Local\\Temp\\pip-record-avgyzqqo\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\sneha\\anaconda3\\Include\\cupy' Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cupy\n",
      "  Using cached cupy-11.2.0.tar.gz (1.8 MB)\n",
      "Requirement already satisfied: numpy<1.26,>=1.20 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from cupy) (1.21.5)\n",
      "Requirement already satisfied: fastrlock>=0.5 in c:\\users\\sneha\\anaconda3\\lib\\site-packages (from cupy) (0.8)\n",
      "Building wheels for collected packages: cupy\n",
      "  Building wheel for cupy (setup.py): started\n",
      "  Building wheel for cupy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for cupy\n",
      "Failed to build cupy\n",
      "Installing collected packages: cupy\n",
      "    Running setup.py install for cupy: started\n",
      "    Running setup.py install for cupy: finished with status 'error'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#!pip install cupy\u001b[39;00m\n\u001b[0;32m     20\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install cupy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#!pip install cudf\u001b[39;00m\n\u001b[0;32m     23\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install cudf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "! wandb login $secret_value_0\n",
    "!pip install wandb\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from wordcloud import STOPWORDS as stopwords_wc\n",
    "from statsmodels.tsa.stattools import adfuller       ### Augmented Dickey Fuller\n",
    "#!pip install cupy\n",
    "get_ipython().system('pip install cupy')\n",
    "import cupy\n",
    "#!pip install cudf\n",
    "get_ipython().system('pip install cudf')\n",
    "import cudf\n",
    "\n",
    "import cuml\n",
    "from cuml.tsa.arima import ARIMA\n",
    "\n",
    "# Color palette\n",
    "my_colors = [\"#ce8f5a\", \"#efd199\", \"#80c8bc\", \"#5ec0ca\", \"#6287a2\"]\n",
    "sns.palplot(sns.color_palette(my_colors))\n",
    "\n",
    "# Set Style\n",
    "sns.set_style(\"white\")\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "class color:\n",
    "    BOLD = '\\033[1m' + '\\033[93m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "# W&B\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "# Secrets 🤫\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6537417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_png(x, y, path, ax, zoom, offset):\n",
    "    '''For adding other .png images to the graph.\n",
    "    source: https://stackoverflow.com/questions/61971090/how-can-i-add-images-to-bars-in-axes-matplotlib'''\n",
    "    \n",
    "    img = plt.imread(path)\n",
    "    im = OffsetImage(img, zoom=zoom)\n",
    "    im.image.axes = ax\n",
    "    x_offset = offset\n",
    "    ab = AnnotationBbox(im, (x, y), xybox=(x_offset, 0), frameon=False,\n",
    "                        xycoords='data', boxcoords=\"offset points\", pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    \n",
    "\n",
    "    \n",
    "def show_values_on_bars(axs, h_v=\"v\", space=0.4):\n",
    "    '''Plots the value at the end of the a seaborn barplot.\n",
    "    axs: the ax of the plot\n",
    "    h_v: weather or not the barplot is vertical/ horizontal'''\n",
    "    \n",
    "    def _show_on_single_plot(ax):\n",
    "        if h_v == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_height())\n",
    "                ax.text(_x, _y, format(value, ','), ha=\"center\") \n",
    "        elif h_v == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_width())\n",
    "                ax.text(_x, _y, format(value, ','), ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "        \n",
    "\n",
    "\n",
    "def emoji_extractor(string, remove=False):\n",
    "    '''Removes Emoji from a text.'''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    if remove == False:\n",
    "        # Extract emoji\n",
    "        return emoji_pattern.findall(string)\n",
    "    else:\n",
    "        # Remove emoji from text\n",
    "        return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def clean_emoji(x):\n",
    "    if len(x) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return x[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "def clean_tweets(df):\n",
    "    '''Returns the dataframe with the tweet column cleaned.'''\n",
    "    \n",
    "    # ----- Remove \\n, \\t, \\xa0 -----\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\n', ''))\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\xa0', ''))\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\t', ''))\n",
    "    \n",
    "    # ----- Remove pic.twitter and http:// + https:// links -----\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'https\\S+', '', x))\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'pic.twitter\\S+', '', x))\n",
    "    \n",
    "    # ----- Remove mentions and hashtags -----\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'#\\S+', '', x))\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'@\\S+', '', x))\n",
    "    \n",
    "    # ----- Extract Emojis and Remove from Tweet -----\n",
    "    df['tweet_emojis'] = df['tweet'].apply(lambda x: emoji_extractor(x, remove=False))\n",
    "    df['tweet_emojis'].replace('', np.nan, inplace=True)\n",
    "#     df[\"tweet_emojis\"] = df[\"tweet_emojis\"].apply(lambda x: clean_emoji(x))\n",
    "    \n",
    "    df['tweet'] = df['tweet'].apply(lambda x: emoji_extractor(x, remove=True))\n",
    "    \n",
    "    # ----- Strip of whitespaces -----\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: x.strip())\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x.split()))\n",
    "    \n",
    "    # ----- Remove punctuation & Make lowercase -----\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: x.lower())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83368f42",
   "metadata": {},
   "source": [
    "# Elon Musk's personality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32251f6d",
   "metadata": {},
   "source": [
    "* Let's see how his tweets look, his tweets progression over time and get an overall feel of how, what, when he tweets.\n",
    "This will help us understand about his behavior, as well as address and analyse the tweets that mention Bitcoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tweets ===\n",
    "tweets = pd.read_csv(\"TweetsElonMusk.csv\")\n",
    "tweets = tweets[[\"id\", \"date\", \"time\", \"username\", \n",
    "                 \"tweet\", \"mentions\", \"urls\", \"photos\", \"replies_count\", \n",
    "                 \"retweets_count\", \"likes_count\", \"hashtags\", \"link\"]]\n",
    "\n",
    "# Create new features\n",
    "tweets[\"year\"] = tweets[\"date\"].apply(lambda x: x.split(\"-\")[0])\n",
    "# Clean Tweets\n",
    "tweets = clean_tweets(df=tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly evolution\n",
    "date_count_df = tweets[tweets[\"year\"]!=\"2021\"].groupby(\"year\")[\"tweet\"].count().reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(25, 11))\n",
    "ax = sns.lineplot(data=date_count_df, x=\"year\", y=\"tweet\", lw=8)\n",
    "plt.title(\"Tweet Count Evolution\", size=25)\n",
    "plt.xlabel(\"Year\", size=20)\n",
    "plt.ylabel(\"Frequency\", size=20)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "addd9487",
   "metadata": {},
   "source": [
    "Conclusion: he tweets few times in a year from 2010 to 2014. The year 2015 was his breaking point, when he started tweeting more and more every year. It's also the year when Elon became the rockstar.\n",
    "    but in the year 2015 he reached at the new level, by announcing Tesla's Powerwall battery and putting out his personal life through his biography."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228be6c",
   "metadata": {},
   "source": [
    "# * We want to explore more about his personality. We want to plot his like counts, retweets count and replies counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wandb_lineplot(x_data, y_data, x_name, y_name, title, log):\n",
    "    '''Create and save barplot in W&B Environment.\n",
    "    x_data & y_data: Pandas Series containing x & y data\n",
    "    x_name & y_name: strings containing axis names\n",
    "    title: title of the graph\n",
    "    log: string containing name of log'''\n",
    "    \n",
    "    # Save Graph in W&B Dashboard as well\n",
    "    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n",
    "\n",
    "    table = wandb.Table(data=data, columns = [x_name, y_name])\n",
    "    wandb.log({log : wandb.plot.line(table, x_name, y_name,\n",
    "                                                  title=title)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Popularity Information\n",
    "popularity = [\"likes_count\", \"retweets_count\", \"replies_count\"]\n",
    "popularity_df = tweets[tweets[\"year\"]!=\"2021\"].groupby(\"year\").agg({popularity[0] : 'sum',\n",
    "                                                                    popularity[1] : 'sum',\n",
    "                                                                    popularity[2] : 'sum',\n",
    "                                                                    'tweet' : 'count'}).reset_index()\n",
    "popularity_df[\"likes_count\"] = popularity_df[\"likes_count\"]/popularity_df[\"tweet\"]\n",
    "popularity_df[\"retweets_count\"] = popularity_df[\"retweets_count\"]/popularity_df[\"tweet\"]\n",
    "popularity_df[\"replies_count\"] = popularity_df[\"replies_count\"]/popularity_df[\"tweet\"]\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(25, 15))\n",
    "axs = [ax1, ax2, ax3]\n",
    "plt.suptitle(\"Popularity\", size=25)\n",
    "sns.barplot(data=popularity_df, x=\"year\", y=\"likes_count\", lw=5, ax=ax1)\n",
    "sns.barplot(data=popularity_df, x=\"year\", y=\"retweets_count\", lw=5,  ax=ax2)\n",
    "sns.barplot(data=popularity_df, x=\"year\", y=\"replies_count\", lw=5,  ax=ax3)\n",
    "names = [\"Average Likes\", \"Average Retweets\", \"Average Replies\"]\n",
    "for ax, n in zip(axs, names):\n",
    "    ax.set_xlabel(\"\", size=20)\n",
    "    ax.set_ylabel(n, size=20)\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "#     ax.title.set_text(n)\n",
    "    show_values_on_bars(axs=ax, h_v=\"v\", space=0.4)\n",
    "sns.despine(left=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data, mask=None, title=\"\"):\n",
    "    text = \" \".join(t for t in data.dropna())\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"t\", \"co\", \"https\", \"amp\", \"U\", \"Comment\", \"text\", \"attr\", \"object\"])\n",
    "    wordcloud = WordCloud(stopwords=stopwords, scale=4, max_font_size=50, max_words=500,mask=mask, background_color=\"white\").generate(text)\n",
    "    fig = plt.figure(1, figsize=(16,16))\n",
    "    plt.axis('off')\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    fig.subplots_adjust(top=2.3)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb619c6e",
   "metadata": {},
   "source": [
    "# Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287628f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wandb_barplot(x_data, y_data, x_name, y_name, title, log):\n",
    "    '''Create and save barplot in W&B Environment.\n",
    "    x_data & y_data: Pandas Series containing x & y data\n",
    "    x_name & y_name: strings containing axis names\n",
    "    title: title of the graph\n",
    "    log: string containing name of log'''\n",
    "    \n",
    "    # Save Graph in W&B Dashboard as well\n",
    "    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n",
    "\n",
    "    table = wandb.Table(data=data, columns = [x_name, y_name])\n",
    "    wandb.log({log : wandb.plot.bar(table, x_name, y_name,\n",
    "                                                  title=title)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(tweets['tweet'], title = 'Prevalent words in tweets')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f0c81d3",
   "metadata": {},
   "source": [
    "Note: A lot of talk about Tesla, rocket, Mars, starship, launch. To be observed that the wording sounds super positive: yes, yeah, good, thank, people, sure. I like that a lot, he's always super positive and enthusiastin in his messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d658232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Bitcoin Information\n",
    "bitcoin_tweets = tweets[tweets[\"tweet\"].str.contains(\"bitcoin\")].reset_index(drop = True)\n",
    "\n",
    "# Information\n",
    "print(\"% of tweets about Bitcoin:\", \"{:.3}%\".format(bitcoin_tweets.shape[0]/tweets.shape[0]*100))\n",
    "top = bitcoin_tweets.sort_values(\"likes_count\", ascending=False)[:10][\"tweet\"]\n",
    "print(\"Most liked BITCOIN tweets:\")\n",
    "for k, text in enumerate(top):\n",
    "    print(f\"{k+1}. {text}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve only dogecoin Information\n",
    "dogecoin_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n",
    "\n",
    "# Information\n",
    "print(\"% of tweets about Dogecoin:\", \"{:.3}%\".format(dogecoin_tweets.shape[0]/tweets.shape[0]*100))\n",
    "  \n",
    "top = dogecoin_tweets.sort_values(\"likes_count\", ascending=False)[:10][\"tweet\"]\n",
    "print(\"Most liked DOGECOIN tweets:\")\n",
    "for k, text in enumerate(top):\n",
    "    print(f\"{k+1}. {text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cfd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dogecoin ===\n",
    "dogecoin = pd.read_csv(\"E:\\DataScienceProject\\DOGE-USD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7dd6a2",
   "metadata": {},
   "source": [
    "# Is there correlation between Dogecoin and Elon Musk's Tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogecoin .head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e78424",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogecoin .columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74899e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogecoin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogecoin .info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57021d",
   "metadata": {},
   "source": [
    "# Analyze dogecoin Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5255b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 11))\n",
    "plt.plot(dogecoin[\"Date\"], dogecoin[\"Volume\"], lw=3)\n",
    "plt.title(\"dogeconi Volume over time\", size=25)\n",
    "plt.xlabel(\"Time\", size=20)\n",
    "plt.ylabel(\"Volume\", size=20);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5e19e6f",
   "metadata": {},
   "source": [
    "Conclusion: from the above graph, It can be concluded that volume of dogecoin is increasing with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bitcoin info\n",
    "dgc_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n",
    "# Convert date to number\n",
    "dgc_tweets[\"date\"] = dgc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n",
    "timestamps = dgc_tweets[\"date\"]\n",
    "\n",
    "dgc_prices = dogecoin.sort_values(\"Date\", ascending=False).head(800)\n",
    "dgc_prices[\"Date\"] = dgc_prices[\"Date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n",
    "\n",
    "for k, tweet in enumerate(dgc_tweets[\"tweet\"]): print(f\"{k+1}.\", tweet)\n",
    "\n",
    "# Get intersection\n",
    "x_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Date\"]\n",
    "y_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Adj Close\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize = (25, 11))\n",
    "for x, y in zip(x_values, y_values):\n",
    "    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\n",
    "plt.plot(dgc_prices[\"Date\"], dgc_prices[\"Adj Close\"], lw=3, zorder=1)\n",
    "plt.title(\"Dogecoin Price & Elon's Tweets\", size=25)\n",
    "plt.xlabel(\"Time\", size=20)\n",
    "plt.ylabel(\"$ Price\", size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69319bf",
   "metadata": {},
   "source": [
    "* Closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8367b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgc_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n",
    "# Convert date to number\n",
    "dgc_tweets[\"date\"] = dgc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n",
    "timestamps = dgc_tweets[\"date\"]\n",
    "\n",
    "dgc_prices = dogecoin.sort_values(\"Date\", ascending=False).head(90)\n",
    "dgc_prices[\"Date\"] = dgc_prices[\"Date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n",
    "\n",
    "for k, tweet in enumerate(dgc_tweets[\"tweet\"][:6]): print(f\"{k+1}.\", tweet)\n",
    "\n",
    "# Get intersection\n",
    "x_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Date\"]\n",
    "y_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Adj Close\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize = (25, 11))\n",
    "for x, y in zip(x_values, y_values):\n",
    "    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\n",
    "plt.plot(dgc_prices[\"Date\"], dgc_prices[\"Adj Close\"], lw=3, zorder=1)\n",
    "plt.title(\"Dogecoin Price & Elon's Tweets\", size=25)\n",
    "plt.xlabel(\"Time\", size=20)\n",
    "plt.ylabel(\"$ Price\", size=20);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea8ce7fe",
   "metadata": {},
   "source": [
    "Conclusion: from the above two graphs, It can be concluded that there is a positive correlation between Elon Musk’s tweets and dogecoin. When Elon Musk tweets for dogecoin, dogecoin proice increased as per last two graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e02903",
   "metadata": {},
   "source": [
    "# Analyze time series data for dogecoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb51cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 11))\n",
    "plt.plot(dogecoin[\"Date\"], dogecoin[\"Close\"], lw=3)\n",
    "plt.title(\"dogeconi Close over time\", size=25)\n",
    "plt.xlabel(\"Time\", size=20)\n",
    "plt.ylabel(\"Volume\", size=20);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0276379",
   "metadata": {},
   "source": [
    "Conclusion: from the above graph, It can be concluded that Close price of dogecoin is increased when Elon Musk tweets about dogecoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1aed1",
   "metadata": {},
   "source": [
    "# Test Stationarity for the time series data dogecoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd51bca",
   "metadata": {},
   "source": [
    "Our time series data can have a trend or not. It is of the utmost importance to determine how the series is behaving before applying any model to it.\n",
    "\n",
    "Augmented Dicky Fuller test: it determines how strongly a time series is defined by a trend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9adb5",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\n",
    "Null Hypothesis (H0): Null hypothesis of the test is that the time series can be represented by a unit root that is not stationary.\n",
    "Alternative Hypothesis (H1): Alternative Hypothesis of the test is that the time series is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac089179",
   "metadata": {},
   "source": [
    "Why is Stationarity Important?\n",
    "For data to be stationary, the statistical properties of a system do not change over time. This does not mean that the values for each data point have to be the same, but the overall behavior of the data should remain constant.\n",
    "\n",
    "If the data is non-stationary (meaning it has a trend), we need to remove it in order to proceed with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0aca73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
